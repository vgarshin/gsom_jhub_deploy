proxy:
  secretToken: "<SECRET_TOKEN>"
  # chp relates to the proxy pod, which is responsible for routing traffic based
  # on dynamic configuration sent from JupyterHub to CHP's REST API
  chp:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/configurable-http-proxy
      tag: "4.6.1"
  # traefik relates to the autohttps pod, which is responsible for TLS
  # termination when proxy.https.type=letsencrypt
  traefik:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/traefik
      tag: "v2.10.5"
  secretSync:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-secret-sync
      tag: "3.2.0"
  https:
    enabled: true
    hosts:
      - <HOST_NAME>
    letsencrypt:
      contactEmail: vgarshin@vtb.education

scheduling:
# ==========================================
# This priority mechanism allows us to add dummy users or user-placeholders 
# with low priority that can take up resources until a real user with 
# (higher priority) requires it
  podPriority:
    enabled: true
    globalDefault: true
    defaultPriority: 10
    userPlaceholderPriority: 0
# uncomment following lines to add dummy users
  userPlaceholder:
    enabled: true
    replicas: 3
# ==========================================
# The user schedulerâ€™s only task is to schedule new user pods to the most utilized node
  userScheduler:
    enabled: true
# ==========================================
# If we add a taint to all the nodes in the node pool, and a toleration on the user pods 
# to tolerate being scheduled on a tainted node, we have practically dedicated the node pool 
# to be used only by user pods
#  scheduling:
#    userPods:
#      nodeAffinity:
#        matchNodePurpose valid options:
#          - ignore
#          - prefer (the default)
#          - require
#        matchNodePurpose: require
# ==========================================
# With the hook-image-puller enabled (the default), the user images being introduced 
# will be pulled to the nodes before the hub pod is updated to utilize the new image.
prePuller:
  hook:
    enabled: true
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-image-awaiter
      tag: "3.2.0"

# ==========================================
# Secret for container registry password
# NOTE - password's lifetime is 1 year !!!
imagePullSecret:
  create: true
  registry: <CR_NAME>
  username: oauth
  email: vgarshin@yandex.ru
  password: <CONTAINER_REGISTRY_PASSWORD>

singleuser:
  networkTools:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-network-tools
      tag: "3.2.0"
  image:
    name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-singleuser-sample
    tag: "3.2.0"
# ==========================================
# git clone repository at start for user
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "bash"
          - "-c"
          - >
            git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
            mkdir -p /home/jovyan/__MANUAL;
            rm -r /home/jovyan/__MANUAL/*;
            mv -f /tmp/manual/* /home/jovyan/__MANUAL;
            mkdir -p /home/jovyan/.local/share/jupyter/metadata;
            mkdir -p /home/jovyan/.local/share/jupyter/metadata/code-snippets;
            mv /home/jovyan/__MANUAL/code-snippets/* /home/jovyan/.local/share/jupyter/metadata/code-snippets/
# ==========================================
# databases credentials
  extraEnv:
    CLICKHOUSE_USER: "<CLICKHOUSE_LOGIN>"
    CLICKHOUSE_PASSWORD: "<CLICKHOUSE_PASSWORD>"
    POSTGRESQL_USER: "<POSTGRESQL_LOGIN>"
    POSTGRESQL_PASSWORD: "<POSTGRESQL_PASSWORD>"
# ==========================================
# timeout for user's server start
  startTimeout: 900
# ==========================================
# 5 users per node config
  cpu:
    limit: 3
    guarantee: 2
  memory:
    limit: 10G
    guarantee: 8G
  nodeSelector:
    NODETYPE: CPU
# ==========================================
# 3 users per node config
#  cpu:
#    limit: 5
#    guarantee: 4
#  memory:
#    limit: 18G
#    guarantee: 16G
# ==========================================
  image:
    name: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_NAME>
    tag: <DOCKER_IMAGE_DSAI_TAG>
  profileList:
    - display_name: "Data Science environment"
      description: "All libraries for Data Science courses and labs."
      default: true
    - display_name: "Minimal Python environment"
      description: "Pure Python with some libraries and Unix man packages."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_MINPY_NAME>:<DOCKER_IMAGE_MINPY_TAG>
        cpu_guarantee: 1
        cpu_limit: 2
        mem_guarantee: 2G
        mem_limit: 4G
    - display_name: "Spark environment"
      description: "Jupyter and PySpark image with S3 access."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_SPARK_NAME>:<DOCKER_IMAGE_SPARK_TAG>
        cpu_guarantee: 4
        cpu_limit: 5
        mem_guarantee: 12G
        mem_limit: 16G
    - display_name: "PostgreSQL environment"
      description: "Demo PostgreSQL database for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_PG_NAME>:<DOCKER_IMAGE_PG_TAG>
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "MongoDB environment"
      description: "Demo MongoDB database for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_MONGO_NAME>:<DOCKER_IMAGE_MONGO_TAG>
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S mongod --dbpath /var/lib/mongo --logpath /var/log/mongodb/mongod.log --fork;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "Airflow environment"
      description: "Airflow platform for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_AIR_NAME>:<DOCKER_IMAGE_AIR_TAG>
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: 10G
        mem_limit: 12G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL;
                  mkdir -p /home/jovyan/airflow;
                  yes | cp -rf /usr/local/etc/airflow/airflow.cfg /home/jovyan/airflow/
    - display_name: "Hadoop (with YARN) and Spark environment"
      description: "Hadoop mini-cluster with Map-Reduce operations and standalone Spark."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_HDP_NAME>:<DOCKER_IMAGE_HDP_TAG>
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: 10G
        mem_limit: 12G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service ssh start && sudo runuser hadoop -s /bin/bash -c "export HBASE_HOME=/usr/local/hbase && export HBASE_CONF_DIR=/usr/local/hbase/conf && export PATH=$PATH:$JAVA_HOME/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/hbase/bin:/usr/local/hbase/sbin && export APPLICATION_WEB_PROXY_BASE=user/${JUPYTERHUB_USER}/proxy/8088 && export HADOOP_HOME=/usr/local/hadoop && export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop && /usr/local/hadoop/bin/init/start-hadoop.sh && hdfs dfs -mkdir /jovyan && hdfs dfs -chown -R jovyan:hadoopusers /jovyan && hadoop fs -chmod -R 777 /tmp && start-hbase.sh && hdfs dfs -mkdir /user && hdfs dfs -mkdir /user/hive && hdfs dfs -mkdir /user/hive/warehouse && hdfs dfs -chmod g+w /user/hive/warehouse && hdfs dfs -chown -R jovyan:hadoopusers /user";
                  schematool -dbType derby -initSchema;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "R environment"
      description: "Popular packages from the R ecosystem."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_R_NAME>:<DOCKER_IMAGE_R_TAG>
# ==========================================
# Hadoop client image
#    - display_name: "Hadoop environment"
#      description: "HDFS client for Hadoop cluster access."
#      kubespawner_override:
#        image: vgarshin/mibahadoop:20211503v2
# ==========================================
  storage:
    capacity: 12Gi
    extraVolumes:
      - name: jupyterhub-shared
        persistentVolumeClaim:
          claimName: jupyterhub-shared-pvc
    extraVolumeMounts:
      - name: jupyterhub-shared
        mountPath: /home/jovyan/__SHARED
  allowPrivilegeEscalation: true

cull:
  enabled: true
  timeout: 3600
  every: 600

hub:
  image:
    name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-hub
    tag: "3.2.0"
  config:
    Authenticator:
      admin_users:
        - <JUPYTERHUB_ADMIN>
    JupyterHub:
      admin_access: true
      authenticator_class: azuread
# ==========================================
# not working as expected keep for future
#  extraFiles:
#    miba_creds:
#      mountPath: /etc/jupyterhub/mibacreds.json
# ==========================================
# clone custom JupyterHub templates into a volume
  initContainers:
    - name: git-clone-templates
      image: <CR_NAME>/<CR_ID>/jupyterhub/alpine/git:latest
      args:
        - clone
        - --single-branch
        - --branch=master
        - --depth=1
        - --
        - https://github.com/vgarshin/gsom_jhub_ui.git
        - /etc/jupyterhub/custom
      securityContext:
        runAsUser: 0
      volumeMounts:
        - name: custom-templates
          mountPath: /etc/jupyterhub/custom
  extraVolumes:
    - name: custom-templates
      emptyDir: {}
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom
# ==========================================
  extraConfig:
    templates: |
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom/templates']
    simbaConfig: |
      # =============================================
      # ========== START OF CUSTOM CONFIG ===========
      # =============================================


      # =========== (I) Authentication ==============


      import re
      import json
      from traitlets import List
      from jupyterhub.auth import Authenticator
      from oauthenticator.github import GitHubOAuthenticator
      from oauthenticator.azuread import AzureAdOAuthenticator
      from oauthenticator.oauth2 import OAuthenticator


      class SimbaAzureAdOAuthenticator(AzureAdOAuthenticator):
        def normalize_username(self, username):
          username = username.split('@')[0]
          username = username.lower()
          username = re.sub('[^0-9a-zA-Z]+', '', username)
          username = self.username_map.get(username, username)
          return username


      class SimbaYaOAuthenticator(OAuthenticator):
        def user_info_to_username(self, user_info):
          if callable(self.username_claim):
              username = self.username_claim(user_info)
          else:
              username = user_info.get(self.username_claim, None)
          if not username:
              message = (
                  f'No {self.username_claim} found in {user_info}. Maybe the hub needs to be configured to request more scopes?',
              )
              self.log.error(message)
              raise ValueError(message)
          db_dict = <DB_USERS_02>
          if db_dict:
            return db_dict['<CLIENT_02_PREFIX>' + username]
          else:
            return '<CLIENT_02_PREFIX>' + username


      # based on https://github.com/jupyterhub/oauthenticator/issues/136
      class MultiOAuthenticator(Authenticator):
        authenticators = List(help='Authenticators to use', config=True)

        def __init__(self, *arg, **kwargs):
          super().__init__(*arg, **kwargs)
          self._authenticators = []
          for auth_class, url_scope, configs in self.authenticators:
            instance = auth_class(**configs)
            login_url = instance.login_url('')
            instance._url_scope = url_scope
            instance._login_url = login_url
            
            def custom_login_url(self, base_url):
              return url_path_join(base_url, self._url_scope, self._login_url)
            
            instance.login_url = custom_login_url.__get__(instance, auth_class)
            self._authenticators.append({
              'instance': instance,
              'url_scope': url_scope,
            })
        
        def get_handlers(self, app):
          routes = []
          for _auth in self._authenticators:
            for path, handler in _auth['instance'].get_handlers(app):

              class SubHandler(handler):
                  authenticator = _auth['instance']

              routes.append((f'{_auth["url_scope"]}{path}', SubHandler))
          print('routes', routes)
          return routes
        
        def get_custom_html(self, base_url):
          html = [
            '<div class="service-login">',
            '<h1 class="text-center">Welcome to SimBA</h1>',
            """
            <p style="text-align:center">
              SimBA or Simulation platform for Business Analytics and Big Data is a flexible and powerful tool<br>
              for the students, teachers and researches of Graduate School of Management SPbU (GSOM SPbU).<br>
              The platform is based on JupyterHub and it is free for all users with GSOM account<br>
              <br>
              Join our <a href="https://t.me/simbaplatform" target="_blank">SimBA channel</a> to keep up to date with SimBA's events<br>
              and may the Force of Data Analytics be with You!
            </p>
            """,
            """
            <p id='insecure-login-warning' class='hidden'>
            Warning: JupyterHub seems to be served over an unsecured HTTP connection.
            We strongly recommend enabling HTTPS for JupyterHub.
            </p>
            """
          ]
          for authenticator in self._authenticators:
            login_service = authenticator['instance'].login_service or "Local User"
            url = authenticator['instance'].login_url(base_url)
            html.append(
              f"""
              <div style="margin-bottom:10px;">
                <a style="width:30%;" role="button" class='btn btn-jupyter btn-lg' href='{url}'>
                Sign in with {login_service}
                </a>
              </div>
              """
            )
          footer_html = [
            """
            <div class="contentRight">
              <a href="https://t.me/simbaplatform">
                <img src="https://storage.yandexcloud.net/gsom-design-elements/simba-logo-nano.png" alt="SimBA logo">
              </a>
            </div>
            """,
            '</div>',
          ]
          return '\n'.join(html + footer_html)

      
      c.MultiOAuthenticator.authenticators = [
        (SimbaAzureAdOAuthenticator, '/azuread', {
          'tenant_id': '<TENANT_01_ID>',
          'client_id': '<CLIENT_01_ID>',
          'client_secret': '<CLIENT_01_SECRET>',
          'oauth_callback_url': 'https://<HOST_NAME>/hub/azuread/oauth_callback',
          'username_claim': 'unique_name',
          'allow_all': True,
          #'allowed_users': <ALLOWED_USERS_01>
        }),
        (SimbaYaOAuthenticator, '/yandexid', {
          'client_id': '<CLIENT_02_ID>',
          'client_secret': '<CLIENT_02_SECRET>',
          'oauth_callback_url': 'https://<HOST_NAME>/hub/yandexid/oauth_callback',
          'login_service': 'Yandex.Passport',
          'username_claim':'login',
          'authorize_url': 'https://oauth.yandex.ru/authorize',
          'token_url': 'https://oauth.yandex.ru/token',
          'userdata_url': 'https://login.yandex.ru/info',
          #'allow_all': True,
          'allowed_users': <ALLOWED_USERS_02>
        })
      ]
      c.JupyterHub.authenticator_class = MultiOAuthenticator


      # ===== (2) Advanced users configuration ======
      

      # advanced instances for selected users (option 1)
      async def miba_options_form(spawner):
        username = spawner.user.name
        try: 
          
          # Data Science AI bot 
          if (username in <ADVANCED_HW_USERS_DS_LLM>):
            cpu_limit = 5
            mem_limit = '16G'
            cpu_guarantee = 4
            mem_guarantee = '12G'
            spawner.profile_list.extend([
              {
                'display_name': 'Data Science environment with LLM',
                'description': f'All libraries for Data Science courses with AI assistant: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'datascience-environment-adv-llm',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_LLM_NAME>:<DOCKER_IMAGE_LLM_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')

          # Data Science advanced hardware 
          if (username in <ADVANCED_HW_USERS_DS>):
            cpu_limit = 8
            mem_limit = '32G'
            cpu_guarantee = 6
            mem_guarantee = '24G'
            spawner.profile_list.extend([
              {
                'display_name': 'DataScience environment (advanced)',
                'description': f'All libraries for MiBA courses and labs with advanced hardware: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'datascience-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_ADV_NAME>:<DOCKER_IMAGE_DSAI_ADV_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')
          
          # Spark advanced hardware
          if (username in <ADVANCED_HW_USERS_SPARK>):
            cpu_limit = 10
            mem_limit = '40G'
            cpu_guarantee = 8
            mem_guarantee = '32G'
            spawner.profile_list.extend([
              {
                'display_name': 'Spark environment (advanced)',
                'description': f'Jupyter and PySpark image with S3 access with advanced hardware: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'spark-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_SPARK_NAME>:<DOCKER_IMAGE_SPARK_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')

          # GPU advanced hardware
          if (username in <ADVANCED_HW_USERS_GPU>):
            cpu_limit = 8
            mem_limit = '40G'
            cpu_guarantee = 4
            mem_guarantee = '20G'
            spawner.profile_list.extend([
              {
                'display_name': 'GPU environment (advanced)',
                'description': f'GPU  test hardware: 1 GPU / {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'gpu-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_ADV_NAME>:<DOCKER_IMAGE_DSAI_ADV_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee,
                    'extra_resource_limits': {'nvidia.com/gpu': '1'},
                    'node_selector': {'NODETYPE': 'GPU'}
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f"Spawning sever for {username} with advanced configuration option")

        except Exception as e:
          spawner.log.info(f'Exception in user {username} advanced configuration option: ' + str(e))
          pass
        return spawner._options_form_default()

      c.KubeSpawner.options_form = miba_options_form
     

      # ==== (3) Extra folders mount for users ======
     

      from kubespawner.utils import get_k8s_model
      from kubernetes_asyncio import client
      from kubernetes_asyncio.client.models import (V1Volume, V1VolumeMount)
      
      mnt_data = {
        'name': 'jupyterhub-data',
        'pvc': 'jupyterhub-data-pvc',
        'mountPath': '/home/jovyan/__DATA'
      }
      data_folder_users = <DATA_FOLDER_USERS>


      def modify_pod_hook(spawner, pod):
        try:
          # mount DATA folder
          user = spawner.user.name
          read_only_flag = False if (user in data_folder_users) else True
          pod.spec.volumes.append(
            get_k8s_model(V1Volume, {
              'name' : mnt_data['name'],
              'persistentVolumeClaim': {
                'claimName': mnt_data['pvc']
              }
            })
          )
          pod.spec.containers[0].volume_mounts.append(
            get_k8s_model(V1VolumeMount, {
                'name' : mnt_data['name'],
                'mountPath' : mnt_data['mountPath'],
                'readOnly': read_only_flag
            })
          )
          # mount PROJECTS folders
          data_projects_users = <DATA_PROJECTS_USERS>
          for prj in data_projects_users:
            if user in prj['users']:
              pod.spec.volumes.append(
                get_k8s_model(V1Volume, {
                  'name' : 'jupyterhub-{}-data'.format(prj['name']),
                  'persistentVolumeClaim': {
                    'claimName': 'jupyterhub-{}-data-pvc'.format(prj['name'])
                  }
                })
              )
              pod.spec.containers[0].volume_mounts.append(
                get_k8s_model(V1VolumeMount, {
                  'name' : 'jupyterhub-{}-data'.format(prj['name']),
                  'mountPath' : '/home/jovyan/{}'.format(prj['path']),
                  'readOnly': False
                })
              )
        except Exception as e:
          spawner.log.info('Exception in shared-mounts: ' + str(e))
          pass
        return pod
      c.KubeSpawner.modify_pod_hook = modify_pod_hook
      
      # =============================================
      # =========== END OF CUSTOM CONFIG ============
      # =============================================
