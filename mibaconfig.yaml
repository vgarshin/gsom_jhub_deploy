proxy:
  secretToken: "<SECRET_TOKEN>"
  # chp relates to the proxy pod, which is responsible for routing traffic based
  # on dynamic configuration sent from JupyterHub to CHP's REST API.
  chp:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/configurable-http-proxy
      tag: "4.6.1"
  # traefik relates to the autohttps pod, which is responsible for TLS
  # termination when proxy.https.type=letsencrypt.
  traefik:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/traefik
      tag: "v2.10.5"
  secretSync:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-secret-sync
      tag: "3.2.0"
  https:
    enabled: true
    hosts:
      - <HOST_NAME>
    letsencrypt:
      contactEmail: vgarshin@vtb.education

scheduling:
# ==========================================
# This priority mechanism allows us to add dummy users or user-placeholders 
# with low priority that can take up resources until a real user with 
# (higher priority) requires it. 
  podPriority:
    enabled: true
    globalDefault: true
    defaultPriority: 10
    userPlaceholderPriority: 0
  userPlaceholder:
    enabled: true
    replicas: 3
# ==========================================
# The user schedulerâ€™s only task is to schedule new user pods to the most utilized node.
  userScheduler:
    enabled: true
# ==========================================
# If we add a taint to all the nodes in the node pool, and a toleration on the user pods 
# to tolerate being scheduled on a tainted node, we have practically dedicated the node pool 
# to be used only by user pods. 
#  scheduling:
#    userPods:
#      nodeAffinity:
#        matchNodePurpose valid options:
#          - ignore
#          - prefer (the default)
#          - require
#        matchNodePurpose: require
# ==========================================
# With the hook-image-puller enabled (the default), the user images being introduced 
# will be pulled to the nodes before the hub pod is updated to utilize the new image.
prePuller:
  hook:
    enabled: true
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-image-awaiter
      tag: "3.2.0"

# ==========================================
# Secret for container registry
# password lifetime 1 year !!!
imagePullSecret:
  create: true
  registry: <CR_NAME>
  username: oauth
  email: vgarshin@yandex.ru
  password: <CONTAINER_REGISTRY_PASSWORD>

singleuser:
  networkTools:
    image:
      name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-network-tools
      tag: "3.2.0"
  image:
    name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-singleuser-sample
    tag: "3.2.0"
# ==========================================
# git clone repository at start for user
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "bash"
          - "-c"
          - >
            git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
            mkdir -p /home/jovyan/__MANUAL;
            rm -r /home/jovyan/__MANUAL/*;
            mv -f /tmp/manual/* /home/jovyan/__MANUAL;
            mkdir -p /home/jovyan/.local/share/jupyter/metadata;
            mkdir -p /home/jovyan/.local/share/jupyter/metadata/code-snippets;
            mv /home/jovyan/__MANUAL/code-snippets/* /home/jovyan/.local/share/jupyter/metadata/code-snippets/
# ==========================================
# local DBs creds
  extraEnv:
    CLICKHOUSE_USER: "<CLICKHOUSE_LOGIN>"
    CLICKHOUSE_PASSWORD: "<CLICKHOUSE_PASSWORD>"
    POSTGRESQL_USER: "<POSTGRESQL_LOGIN>"
    POSTGRESQL_PASSWORD: "<POSTGRESQL_PASSWORD>"
# ==========================================
# JupyterLab turn on-off 
#  defaultUrl: "/lab"
# ==========================================
# timeout to user's server start
  startTimeout: 900
# ==========================================
# 5 users per node config
  cpu:
    limit: 3
    guarantee: 2
  memory:
    limit: 10G
    guarantee: 8G
  nodeSelector:
    NODETYPE: CPU
# ==========================================
# 3 users per node config
#  cpu:
#    limit: 5
#    guarantee: 4
#  memory:
#    limit: 18G
#    guarantee: 16G
# ==========================================
  image:
    name: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_NAME>
    tag: <DOCKER_IMAGE_DSAI_TAG>
  profileList:
    - display_name: "Data Science environment"
      description: "All libraries for Data Science courses and labs."
      default: true
    - display_name: "Minimal Python environment"
      description: "Pure Python with some libraries and Unix man packages."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_MINPY_NAME>:<DOCKER_IMAGE_MINPY_TAG>
        cpu_guarantee: 1
        cpu_limit: 2
        mem_guarantee: 2G
        mem_limit: 4G
    - display_name: "Spark environment"
      description: "Jupyter and PySpark image with S3 access."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_SPARK_NAME>:<DOCKER_IMAGE_SPARK_TAG>
        cpu_guarantee: 4
        cpu_limit: 5
        mem_guarantee: 12G
        mem_limit: 16G
    - display_name: "PostgreSQL environment"
      description: "Demo PostgreSQL database for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_PG_NAME>:<DOCKER_IMAGE_PG_TAG>
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "MongoDB environment"
      description: "Demo MongoDB database for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_MONGO_NAME>:<DOCKER_IMAGE_MONGO_TAG>
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S mongod --dbpath /var/lib/mongo --logpath /var/log/mongodb/mongod.log --fork;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "Airflow environment"
      description: "Airflow platform for the local experiments."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_AIR_NAME>:<DOCKER_IMAGE_AIR_TAG>
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: 10G
        mem_limit: 12G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL;
                  mkdir -p /home/jovyan/airflow;
                  yes | cp -rf /usr/local/etc/airflow/airflow.cfg /home/jovyan/airflow/
    - display_name: "Hadoop (with YARN) and Spark environment"
      description: "Hadoop mini-cluster with Map-Reduce operations and standalone Spark."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_HDP_NAME>:<DOCKER_IMAGE_HDP_TAG>
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: 10G
        mem_limit: 12G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "bash"
                - "-c"
                - >
                  echo redspot | sudo -S service ssh start && sudo runuser hadoop -s /bin/bash -c "export HBASE_HOME=/usr/local/hbase && export HBASE_CONF_DIR=/usr/local/hbase/conf && export PATH=$PATH:$JAVA_HOME/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/hbase/bin:/usr/local/hbase/sbin && export APPLICATION_WEB_PROXY_BASE=user/${JUPYTERHUB_USER}/proxy/8088 && export HADOOP_HOME=/usr/local/hadoop && export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop && /usr/local/hadoop/bin/init/start-hadoop.sh && hdfs dfs -mkdir /jovyan && hdfs dfs -chown -R jovyan:hadoopusers /jovyan && hadoop fs -chmod -R 777 /tmp && start-hbase.sh && hdfs dfs -mkdir /user && hdfs dfs -mkdir /user/hive && hdfs dfs -mkdir /user/hive/warehouse && hdfs dfs -chmod g+w /user/hive/warehouse && hdfs dfs -chown -R jovyan:hadoopusers /user";
                  schematool -dbType derby -initSchema;
                  git clone https://github.com/vgarshin/gsom_jhub_manual /tmp/manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/manual/* /home/jovyan/__MANUAL
    - display_name: "R environment"
      description: "Popular packages from the R ecosystem."
      kubespawner_override:
        image: <CR_NAME>/<CR_ID>/<DOCKER_IMAGE_R_NAME>:<DOCKER_IMAGE_R_TAG>
# ==========================================
# Hadoop client image
#    - display_name: "Hadoop environment"
#      description: "HDFS client for Hadoop cluster access."
#      kubespawner_override:
#        image: vgarshin/mibahadoop:20211503v2
# ==========================================
  storage:
    capacity: 12Gi
    extraVolumes:
      - name: jupyterhub-shared
        persistentVolumeClaim:
          claimName: jupyterhub-shared-pvc
    extraVolumeMounts:
      - name: jupyterhub-shared
        mountPath: /home/jovyan/__SHARED
  allowPrivilegeEscalation: true

cull:
  enabled: true
  timeout: 3600
  every: 600

hub:
  image:
    name: <CR_NAME>/<CR_ID>/jupyterhub/k8s-hub
    tag: "3.2.0"
  config:
    Authenticator:
      admin_users:
        - <JUPYTERHUB_ADMIN>
    JupyterHub:
      admin_access: true
      authenticator_class: azuread
# ==========================================
# not working as expected keep for future
#  extraFiles:
#    miba_creds:
#      mountPath: /etc/jupyterhub/mibacreds.json
# ==========================================
# clone custom JupyterHub templates into a volume
  initContainers:
    - name: git-clone-templates
      image: <CR_NAME>/<CR_ID>/jupyterhub/alpine/git:latest
      args:
        - clone
        - --single-branch
        - --branch=master
        - --depth=1
        - --
        - https://github.com/vgarshin/gsom_jhub_ui.git
        - /etc/jupyterhub/custom
      securityContext:
        runAsUser: 0
      volumeMounts:
        - name: custom-templates
          mountPath: /etc/jupyterhub/custom
  extraVolumes:
    - name: custom-templates
      emptyDir: {}
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom
# ==========================================
  extraConfig:
    templates: |
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom/templates']
    mibaConfig: |
      # =============== START ====================
      # auth via GSOM Azure AD
      import re
      import json
      from oauthenticator.azuread import AzureAdOAuthenticator

      class MibaAzureAdOAuthenticator(AzureAdOAuthenticator):
        def normalize_username(self, username):
          username = username.split('@')[0]
          username = username.lower()
          username = re.sub('[^0-9a-zA-Z]+', '', username)
          username = self.username_map.get(username, username)
          return username
      
      # for future release of JupyterHub for Kubernetes
      #with open('/etc/jupyterhub/mibacreds.json') as file:
      #  CREDS = json.load(file)
      
      CREDS = {
        'tenant_id': '<TENANT_ID>',
        'client_id': '<CLIENT_ID>',
        'client_secret': '<CLIENT_SECRET>'
      }

      c.JupyterHub.authenticator_class = MibaAzureAdOAuthenticator

      c.MibaAzureAdOAuthenticator.tenant_id = CREDS['tenant_id']
      c.MibaAzureAdOAuthenticator.oauth_callback_url = 'https://<HOST_NAME>/hub/oauth_callback'
      c.MibaAzureAdOAuthenticator.client_id = CREDS['client_id']
      c.MibaAzureAdOAuthenticator.client_secret = CREDS['client_secret']
      c.MibaAzureAdOAuthenticator.username_claim = 'unique_name'
      c.MibaAzureAdOAuthenticator.allow_all = True

      # ==========================================
      # advanced instances for selected users (1)
      async def miba_options_form(spawner):
        username = spawner.user.name
        try: 
          
          # Data Science AI bot 
          if (username in <ADVANCED_HW_USERS_DS_LLM>):
            cpu_limit = 5
            mem_limit = '16G'
            cpu_guarantee = 4
            mem_guarantee = '12G'
            spawner.profile_list.extend([
              {
                'display_name': 'Data Science environment with LLM',
                'description': f'All libraries for Data Science courses with AI assistant: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'datascience-environment-adv-llm',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_LLM_NAME>:<DOCKER_IMAGE_LLM_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')

          # Data Science advanced hardware 
          if (username in <ADVANCED_HW_USERS_DS>):
            cpu_limit = 8
            mem_limit = '32G'
            cpu_guarantee = 6
            mem_guarantee = '24G'
            spawner.profile_list.extend([
              {
                'display_name': 'DataScience environment (advanced)',
                'description': f'All libraries for MiBA courses and labs with advanced hardware: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'datascience-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_ADV_NAME>:<DOCKER_IMAGE_DSAI_ADV_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')
          
          # Spark advanced hardware
          if (username in <ADVANCED_HW_USERS_SPARK>):
            cpu_limit = 10
            mem_limit = '40G'
            cpu_guarantee = 8
            mem_guarantee = '32G'
            spawner.profile_list.extend([
              {
                'display_name': 'Spark environment (advanced)',
                'description': f'Jupyter and PySpark image with S3 access with advanced hardware: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'spark-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_SPARK_NAME>:<DOCKER_IMAGE_SPARK_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f'Spawning sever for {username} with advanced configuration option')

          # GPU advanced hardware
          if (username in <ADVANCED_HW_USERS_GPU>):
            cpu_limit = 8
            mem_limit = '40G'
            cpu_guarantee = 4
            mem_guarantee = '20G'
            spawner.profile_list.extend([
              {
                'display_name': 'GPU environment (advanced)',
                'description': f'GPU  test hardware: 1 GPU / {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'gpu-environment-adv',
                'kubespawner_override':
                  {
                    'image': '<CR_NAME>/<CR_ID>/<DOCKER_IMAGE_DSAI_ADV_NAME>:<DOCKER_IMAGE_DSAI_ADV_TAG>',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee,
                    'extra_resource_limits': {'nvidia.com/gpu': '1'},
                    'node_selector': {'NODETYPE': 'GPU'}
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f"Spawning sever for {username} with advanced configuration option")

        except Exception as e:
          spawner.log.info(f'Exception in user {username} advanced configuration option: ' + str(e))
          pass
        return spawner._options_form_default()

      c.KubeSpawner.options_form = miba_options_form
     
      # ==========================================
      # advanced instances for selected users (2)
      #async def miba_pre_spawn_hook(spawner):
      #  username = spawner.user.name
      #  if (username in <ADVANCED_HW_USERS>):
      #    spawner.log.info(f'Spawning sever for {username} with advanced configuration')
      #    spawner.cpu_limit = 7
      #    spawner.mem_limit = '28G'
      #c.KubeSpawner.pre_spawn_hook = miba_pre_spawn_hook

      # ==========================================
      mnt_data = {
        'name': 'jupyterhub-data',
        'pvc': 'jupyterhub-data-pvc',
        'mountPath': '/home/jovyan/__DATA'
      }
      data_folder_users = <DATA_FOLDER_USERS>
      
      from kubespawner.utils import get_k8s_model
      # older versions of Hub
      #from kubernetes import client
      #from kubernetes.client.models import ( V1Volume, V1VolumeMount )
      # Hub versions since 2.x.x
      from kubernetes_asyncio import client
      from kubernetes_asyncio.client.models import ( V1Volume, V1VolumeMount )
      
      def modify_pod_hook(spawner, pod):
        try:
          # mount DATA folder
          user = spawner.user.name
          read_only_flag = False if (user in data_folder_users) else True
          pod.spec.volumes.append(
            get_k8s_model(V1Volume, {
              'name' : mnt_data['name'],
              'persistentVolumeClaim': {
                'claimName': mnt_data['pvc']
              }
            })
          )
          pod.spec.containers[0].volume_mounts.append(
            get_k8s_model(V1VolumeMount, {
                'name' : mnt_data['name'],
                'mountPath' : mnt_data['mountPath'],
                'readOnly': read_only_flag
            })
          )
          # mount PROJECTS folders
          data_projects_users = <DATA_PROJECTS_USERS>
          for prj in data_projects_users:
            if user in prj['users']:
              pod.spec.volumes.append(
                get_k8s_model(V1Volume, {
                  'name' : 'jupyterhub-{}-data'.format(prj['name']),
                  'persistentVolumeClaim': {
                    'claimName': 'jupyterhub-{}-data-pvc'.format(prj['name'])
                  }
                })
              )
              pod.spec.containers[0].volume_mounts.append(
                get_k8s_model(V1VolumeMount, {
                  'name' : 'jupyterhub-{}-data'.format(prj['name']),
                  'mountPath' : '/home/jovyan/{}'.format(prj['path']),
                  'readOnly': False
                })
              )
        except Exception as e:
          spawner.log.info('Exception in shared-mounts: ' + str(e))
          pass
        return pod
      c.KubeSpawner.modify_pod_hook = modify_pod_hook
      
      # ================= END ====================
