proxy:
  secretToken: "<SECRET_TOKEN>"
  https:
    enabled: true
    hosts:
      - jhas01.gsom.spbu.ru
    letsencrypt:
      contactEmail: vgarshin@vtb.education

scheduling:
# ==========================================
# This priority mechanism allows us to add dummy users or user-placeholders 
# with low priority that can take up resources until a real user with 
# (higher priority) requires it. 
#  podPriority:
#    enabled: true
#    globalDefault: true
#    defaultPriority: 10
#    userPlaceholderPriority: 0
#  userPlaceholder:
#    enabled: true
#    replicas: 2
# ==========================================
# The user schedulerâ€™s only task is to schedule new user pods to the most utilized node.
  userScheduler:
    enabled: true
# ==========================================
# If we add a taint to all the nodes in the node pool, and a toleration on the user pods 
# to tolerate being scheduled on a tainted node, we have practically dedicated the node pool 
# to be used only by user pods. 
#  scheduling:
#    userPods:
#      nodeAffinity:
        # matchNodePurpose valid options:
        # - ignore
        # - prefer (the default)
        # - require
#        matchNodePurpose: require
# ==========================================

singleuser:
# ==========================================
# git clone repository at start for user
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "sh"
          - "-c"
          - >
            cd /tmp;
            git clone https://github.com/vgarshin/gsom_jhub_manual;
            mkdir -p /home/jovyan/__MANUAL;
            rm -r /home/jovyan/__MANUAL/*;
            mv -f /tmp/gsom_jhub_manual/* /home/jovyan/__MANUAL
# ==========================================
# local DBs creds
  extraEnv:
    CLICKHOUSE_USER: "<CLICKHOUSE_LOGIN>"
    CLICKHOUSE_PASSWORD: "<CLICKHOUSE_PASSWORD>"
    POSTGRESQL_USER: "<POSTGRESQL_LOGIN>"
    POSTGRESQL_PASSWORD: "<POSTGRESQL_PASSWORD>"
# ==========================================
# JupyterLab turn on-off 
#  defaultUrl: "/lab"
# ==========================================
# timeout to user's server start
#  startTimeout: 600
# ==========================================
# 5 users per node config
  cpu:
    limit: 3
    guarantee: 3
  memory:
    limit: 10G
    guarantee: 10G
# ==========================================
# 3 users per node config
#  cpu:
#    limit: 5
#    guarantee: 5
#  memory:
#    limit: 18G
#    guarantee: 18G
# ==========================================
  image:
    name: vgarshin/mibadsai
    tag: 20211004v0
  profileList:
    - display_name: "Data Science environment"
      description: "All libraries for MiBA courses and labs."
      default: true
    - display_name: "Spark environment"
      description: "Jupyter and PySpark image with S3 access."
      kubespawner_override:
        image: vgarshin/mibapysparks3:20211002v1
        cpu_guarantee: 5
        cpu_limit: 5
        mem_guarantee: 18G
        mem_limit: 18G
    - display_name: "R environment"
      description: "Popular packages from the R ecosystem."
      kubespawner_override:
        image: jupyter/r-notebook:a0a544e6dc6e
    - display_name: "PostgreSQL environment"
      description: "Demo PostgreSQL database for the local experiments."
      kubespawner_override:
        image: vgarshin/mibapostgres:20210929v0
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "sh"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  cd /tmp;
                  git clone https://github.com/vgarshin/gsom_jhub_manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/gsom_jhub_manual/* /home/jovyan/__MANUAL
    - display_name: "Airflow environment"
      description: "Airflow platform for the local experiments (EXPERIMENTAL)."
      kubespawner_override:
        image: vgarshin/mibaairflow:20211021v0
        cpu_guarantee: 5
        cpu_limit: 5
        mem_guarantee: 18G
        mem_limit: 18G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "sh"
                - "-c"
                - >
                  echo redspot | sudo -S service postgresql start;
                  cd /tmp;
                  git clone https://github.com/vgarshin/gsom_jhub_manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/gsom_jhub_manual/* /home/jovyan/__MANUAL;
                  mkdir -p /home/jovyan/airflow;
                  yes | cp -rf /usr/local/etc/airflow/airflow.cfg /home/jovyan/airflow/
    - display_name: "Hadoop (with YARN) and Spark environment"
      description: "Hadoop mini-cluster with Map-Reduce operations and standalone Spark (EXPERIMENTAL)."
      kubespawner_override:
        image: vgarshin/mibahdpsa:20211008v1
        cpu_guarantee: 5
        cpu_limit: 5
        mem_guarantee: 18G
        mem_limit: 18G
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "sh"
                - "-c"
                - >
                  echo redspot | sudo -S service ssh start && sudo runuser hadoop -s /bin/bash -c "export PATH=$PATH:$JAVA_HOME/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin && export APPLICATION_WEB_PROXY_BASE=user/${JUPYTERHUB_USER}/proxy/8088 && export HADOOP_HOME=/usr/local/hadoop && export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop && /usr/local/hadoop/bin/init/start-hadoop.sh && hdfs dfs -mkdir /jovyan/ && hdfs dfs -chown -R jovyan:hadoopusers /jovyan/ && hadoop fs -chmod -R 777 /tmp";
                  cd /tmp;
                  git clone https://github.com/vgarshin/gsom_jhub_manual;
                  mkdir -p /home/jovyan/__MANUAL;
                  rm -r /home/jovyan/__MANUAL/*;
                  mv -f /tmp/gsom_jhub_manual/* /home/jovyan/__MANUAL
    - display_name: "Minimal Python environment"
      description: "Pure Python with some libraries and Unix man packages."
      kubespawner_override:
        image: vgarshin/mibaminpy:20210917v0
        cpu_guarantee: 1
        cpu_limit: 2
        mem_guarantee: 2G
        mem_limit: 4G
# ==========================================
# Hadoop client image
#    - display_name: "Hadoop environment"
#      description: "HDFS client for Hadoop cluster access."
#      kubespawner_override:
#        image: vgarshin/mibahadoop:20211503v2
# ==========================================
  storage:
    capacity: 12Gi
    extraVolumes:
      - name: jupyterhub-shared
        persistentVolumeClaim:
          claimName: jupyterhub-shared-pvc
    extraVolumeMounts:
      - name: jupyterhub-shared
        mountPath: /home/jovyan/__SHARED

cull:
  enabled: true
  timeout: 3600
  every: 300

hub:
  config:
    Authenticator:
      admin_users:
        - <JUPYTERHUB_ADMIN>
    JupyterHub:
      admin_access: true
      authenticator_class: azuread
# ==========================================
# not working as expected keep for future
  extraFiles:
    miba_creds:
      mountPath: /etc/jupyterhub/mibacreds.json
# ==========================================
  extraConfig:
    mibaConfig: |
      # =============== START ====================
      # auth via GSOM Azure AD
      import re
      import json
      from oauthenticator.azuread import AzureAdOAuthenticator

      class MibaAzureAdOAuthenticator(AzureAdOAuthenticator):
        def normalize_username(self, username):
          username = username.split('@')[0]
          username = username.lower()
          username = re.sub('[^0-9a-zA-Z]+', '', username)
          username = self.username_map.get(username, username)
          return username
      
      # for future release of JupyterHub for Kubernetes
      #with open('/etc/jupyterhub/mibacreds.json') as file:
      #  CREDS = json.load(file)
      
      CREDS = {
        "tenant_id": "<TENANT_ID>",
        "client_id": "<CLIENT_ID>",
        "client_secret": "<CLIENT_SECRET>"
      }

      c.JupyterHub.authenticator_class = MibaAzureAdOAuthenticator

      c.MibaAzureAdOAuthenticator.tenant_id = CREDS['tenant_id']
      c.MibaAzureAdOAuthenticator.oauth_callback_url = 'https://jhas01.gsom.spbu.ru/hub/oauth_callback'
      c.MibaAzureAdOAuthenticator.client_id = CREDS['client_id']
      c.MibaAzureAdOAuthenticator.client_secret = CREDS['client_secret']
      c.MibaAzureAdOAuthenticator.username_claim = 'unique_name'

      # ==========================================
      # advanced instances for selected users (1)
      async def miba_options_form(spawner):
        username = spawner.user.name
        try: 
          if (username in <ADVANCED_HW_USERS>):
            cpu_limit = 7
            mem_limit = '25G'
            cpu_guarantee = 7
            mem_guarantee = '25G'
            spawner.profile_list.extend([
              {
                'display_name': 'DataScience environment (advanced)',
                'description': f'All libraries for MiBA courses and labs with advanced hardware: {cpu_limit} CPU / {mem_limit} RAM.',
                'slug': 'datascience-environment-adv',
                'kubespawner_override':
                  {
                    'image': 'vgarshin/mibadsai:20210917v0',
                    'cpu_limit': cpu_limit,
                    'cpu_guarantee': cpu_guarantee,
                    'mem_limit': mem_limit,
                    'mem_guarantee': mem_guarantee
                  }
              }
            ])
            spawner.profile_list = list({x['display_name']:x for x in spawner.profile_list}.values())
            spawner.log.info(f"Spawning sever for {username} with advanced configuration option")
        except Exception as e:
          spawner.log.info(f"Exception in user {username} advanced configuration option: " + str(e))
          pass
        return spawner._options_form_default()
      c.KubeSpawner.options_form = miba_options_form
     
      # ==========================================
      # advanced instances for selected users (2)
      #async def miba_pre_spawn_hook(spawner):
      #  username = spawner.user.name
      #  if (username in <ADVANCED_HW_USERS>):
      #    spawner.log.info(f"Spawning sever for {username} with advanced configuration")
      #    spawner.cpu_limit = 7
      #    spawner.mem_limit = "28G"
      #c.KubeSpawner.pre_spawn_hook = miba_pre_spawn_hook

      # ==========================================
      mnt_data = {
        'name': 'jupyterhub-data',
        'pvc': 'jupyterhub-data-pvc',
        'mountPath': '/home/jovyan/__DATA'
      }

      data_folder_users = <DATA_FOLDER_USERS>

      from kubernetes import client
      from kubespawner.utils import get_k8s_model
      from kubernetes.client.models import ( V1Volume, V1VolumeMount )

      def modify_pod_hook(spawner, pod):
        try:
          user = spawner.user.name
          read_only_flag = False if (user in data_folder_users) else True
          pod.spec.volumes.append(
            get_k8s_model(V1Volume, {
              'name' : mnt_data['name'],
              'persistentVolumeClaim': {
                'claimName': mnt_data['pvc']
              }
            })
          )
          pod.spec.containers[0].volume_mounts.append(
            get_k8s_model(V1VolumeMount, {
                'name' : mnt_data['name'],
                'mountPath' : mnt_data['mountPath'],
                'readOnly': read_only_flag
            })
          )
        except Exception as e:
          spawner.log.info("Exception in shared-mounts: " + str(e))
          pass
        return pod
      c.KubeSpawner.modify_pod_hook = modify_pod_hook
      
      # ================= END ====================
